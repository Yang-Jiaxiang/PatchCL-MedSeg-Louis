{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06effd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/u5169119/PatchCL-MedSeg-jiyu'\n",
    "dataset_path = '/home/u5169119/dataset/0_data_dataset_voc_950_kidney'\n",
    "output_dir = base_path + '/dataset/splits/kidney'\n",
    "\n",
    "supervised_loss_path = base_path + '/supervised pre training_loss.csv'\n",
    "SSL_loss_path = base_path + '/SSL_loss.csv'\n",
    "\n",
    "voc_mask_color_map = [\n",
    "    [0, 0, 0], #_background\n",
    "    [128, 0, 0] #kidney\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fe5a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(base_path)\n",
    "\n",
    "from utils.transform import Transform\n",
    "from utils.stochastic_approx import StochasticApprox\n",
    "from utils.model import Network\n",
    "from utils.datasets_PASCAL import PascalVOCDataset\n",
    "from utils.queues import Embedding_Queues\n",
    "from utils.CELOSS import CE_loss\n",
    "from utils.patch_utils import _get_patches\n",
    "from utils.aug_utils import batch_augment\n",
    "from utils.get_embds import get_embeddings\n",
    "from utils.const_reg import consistency_cost\n",
    "from utils.plg_loss import PCGJCL\n",
    "from utils.torch_poly_lr_decay import PolynomialLRDecay\n",
    "from utils.loss_file import save_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6362262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "contrastive_batch_size = 128\n",
    "img_size = 256\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "transform = Transform(img_size, num_classes)\n",
    "embd_queues = Embedding_Queues(num_classes)\n",
    "stochastic_approx = StochasticApprox(num_classes,0.5,0.8)\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0426150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "teacher_model = Network()\n",
    "\n",
    "#Turning off gradients for teacher model\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad=False\n",
    "    #Esuring mothe the models have same weight\n",
    "teacher_model.load_state_dict(model.state_dict())\n",
    "model.contrast=False\n",
    "teacher_model.contrast = False\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(dev)\n",
    "teacher_model = nn.DataParallel(teacher_model)\n",
    "teacher_model=teacher_model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8109bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss=CE_loss(num_classes, image_size=img_size)\n",
    "metrics=[smp.utils.metrics.IoU(threshold=0.5)]\n",
    "\n",
    "optimizer_pretrain=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "optimizer_ssl=torch.optim.SGD(model.parameters(),lr=0.007)\n",
    "scheduler = PolynomialLRDecay(optimizer=optimizer_pretrain, max_decay_steps=200, end_learning_rate=0.0001, power=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af9a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labeled_dataset:  285\n",
      "number of unlabeled_dataset:  570\n",
      "number of val_dataset:  95\n"
     ]
    }
   ],
   "source": [
    "labeled_dataset = PascalVOCDataset(txt_file=output_dir + \"/1-3/labeled.txt\", image_size=img_size, root_dir=dataset_path, labeled=True, colormap=voc_mask_color_map)\n",
    "unlabeled_dataset = PascalVOCDataset(txt_file=output_dir + \"/1-3/unlabeled.txt\", image_size=img_size, root_dir=dataset_path, labeled=False, colormap=voc_mask_color_map)\n",
    "val_dataset = PascalVOCDataset(txt_file=output_dir + \"/val.txt\", image_size=img_size, root_dir=dataset_path, labeled=True)\n",
    "\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print('number of labeled_dataset: ', len(labeled_dataset))\n",
    "print('number of unlabeled_dataset: ', len(unlabeled_dataset))\n",
    "print('number of val_dataset: ', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600fa4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256]) torch.Size([8, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# 測試數據加載器\n",
    "for images, masks in labeled_loader:\n",
    "    print(images.shape, masks.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf2e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel 0 pixel counts: {0.0: 59524, 1.0: 6012}\n",
      "Channel 1 pixel counts: {0.0: 6012, 1.0: 59524}\n",
      "Original masks shape:  torch.Size([8, 256, 256])\n",
      "Multi-channel masks shape:  torch.Size([8, 2, 256, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建一個新的形狀為 [8, 2, 256, 256] 的張量\n",
    "multi_channel_masks = torch.zeros((masks.size(0), 2, masks.size(1), masks.size(2)), dtype=torch.float32)\n",
    "\n",
    "# 將單通道遮罩轉換為多通道遮罩\n",
    "multi_channel_masks[:, 0, :, :] = masks.float()  # 原始遮罩\n",
    "multi_channel_masks[:, 1, :, :] = 1 - masks.float()  # 反轉遮罩\n",
    "\n",
    "# 檢查一個樣本中的唯一值和像素計數\n",
    "imgs_np = multi_channel_masks[0, 0].numpy()\n",
    "unique, counts = np.unique(imgs_np, return_counts=True)\n",
    "pixel_counts = dict(zip(unique, counts))\n",
    "print(\"Channel 0 pixel counts:\", pixel_counts)\n",
    "\n",
    "imgs_np = multi_channel_masks[0, 1].numpy()\n",
    "unique, counts = np.unique(imgs_np, return_counts=True)\n",
    "pixel_counts = dict(zip(unique, counts))\n",
    "print(\"Channel 1 pixel counts:\", pixel_counts)\n",
    "print(\"Original masks shape: \", masks.shape)\n",
    "print(\"Multi-channel masks shape: \", multi_channel_masks.shape)\n",
    "\n",
    "# 顯示原圖和多通道遮罩\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(masks[0].numpy(), cmap='gray')\n",
    "plt.title(\"Original Mask\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(multi_channel_masks[0, 0].numpy(), cmap='gray')\n",
    "plt.title(\"Channel 0 Mask\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(multi_channel_masks[0, 1].numpy(), cmap='gray')\n",
    "plt.title(\"Channel 1 Mask (Inverted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b31db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "#Send psudo masks & imgs to cpu\n",
    "p_masks = multi_channel_masks\n",
    "imgs = images\n",
    "\n",
    "print(imgs.shape)\n",
    "\n",
    "#get classwise patch list\n",
    "patch_list = _get_patches(imgs, p_masks,classes=num_classes,background=True,img_size=img_size,patch_size=contrastive_batch_size)\n",
    "\n",
    "#stochastic approximation filtering and threshold update\n",
    "#qualified_patch_list = stochastic_approx.update(patch_list)\n",
    "qualified_patch_list = patch_list\n",
    "\n",
    "#make augmentations for teacher model\n",
    "augmented_patch_list = batch_augment(qualified_patch_list,contrastive_batch_size)\n",
    "\n",
    "\n",
    "#convert to tensor\n",
    "aug_tensor_patch_list=[]\n",
    "qualified_tensor_patch_list=[]\n",
    "for i in range(len(augmented_patch_list)):\n",
    "    if augmented_patch_list[i] is not None:\n",
    "        aug_tensor_patch_list.append(torch.tensor(augmented_patch_list[i]))\n",
    "        qualified_tensor_patch_list.append(torch.tensor(qualified_patch_list[i]))\n",
    "    else:\n",
    "        aug_tensor_patch_list.append(None)\n",
    "        qualified_tensor_patch_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352c9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_emb_list len:  2\n",
      "teacher_embedding_list len:  2\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m embd_queues\u001b[38;5;241m.\u001b[39menqueue(teacher_embedding_list)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#calculate PCGJCL loss\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m PCGJCL_loss \u001b[38;5;241m=\u001b[39m \u001b[43mPCGJCL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_emb_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membd_queues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m PCGJCL_loss \u001b[38;5;241m=\u001b[39m PCGJCL_loss\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCGJCL_loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, PCGJCL_loss)\n",
      "File \u001b[0;32m~/PatchCL-MedSeg-jiyu/utils/plg_loss.py:53\u001b[0m, in \u001b[0;36mPCGJCL\u001b[0;34m(patch_list, embd_queues, emb_dim, tau, lamb, psi)\u001b[0m\n\u001b[1;32m     51\u001b[0m t_j, mu_j, sig_j\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(embd_queues[j], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), mean_list[j], cov_list[j]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#get hard neg mu_j,sig_j\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m hn_mu_j, hn_sig_j \u001b[38;5;241m=\u001b[39m \u001b[43mhard_neg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# GET HARD NEGS HERE\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#hn_mu_j, hn_sig_j = mu_j, sig_j # USE THIS FOR NO HARD NEGS\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l_count\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/PatchCL-MedSeg-jiyu/utils/hard_neg_mining.py:23\u001b[0m, in \u001b[0;36mhard_neg\u001b[0;34m(samples_p, mean_p, cov_p, samples_n, mean_n, cov_n, beta)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     t_p, mu_p, sig_p, t_n, mu_n, sig_n \u001b[38;5;241m=\u001b[39m samples_p\u001b[38;5;241m.\u001b[39mnumpy(), mean_p\u001b[38;5;241m.\u001b[39mnumpy(), cov_p\u001b[38;5;241m.\u001b[39mnumpy(), samples_n\u001b[38;5;241m.\u001b[39mnumpy(), mean_n\u001b[38;5;241m.\u001b[39mnumpy(), cov_n\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 23\u001b[0m     sig_p_inv, sig_n_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_p\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(sig_n)\n\u001b[1;32m     24\u001b[0m     sig_p_inv, sig_n_inv \u001b[38;5;241m=\u001b[39m sig_p_inv\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e10\u001b[39m, sig_n_inv\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e10\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# calculate mahalanobis dist and find anchors\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:1998\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap(res)\n\u001b[1;32m   1997\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m-> 1998\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhermitian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhermitian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;66;03m# discard small singular values\u001b[39;00m\n\u001b[1;32m   2001\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m rcond[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, newaxis] \u001b[38;5;241m*\u001b[39m amax(s, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:1657\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1656\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1657\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1659\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:98\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "#get embeddings of qualified patches through student model\n",
    "model=model.train()\n",
    "model.module.contrast=True\n",
    "student_emb_list = get_embeddings(model,qualified_tensor_patch_list,True)\n",
    "print('student_emb_list len: ', len(student_emb_list))\n",
    "\n",
    "\n",
    "#get embeddings of augmented patches through teacher model\n",
    "teacher_model.train()\n",
    "teacher_model.module.contrast = True\n",
    "teacher_embedding_list = get_embeddings(teacher_model,aug_tensor_patch_list,False)\n",
    "print('teacher_embedding_list len: ', len(teacher_embedding_list))\n",
    "\n",
    "#enqueue these\n",
    "embd_queues.enqueue(teacher_embedding_list)\n",
    "\n",
    "#calculate PCGJCL loss\n",
    "PCGJCL_loss = PCGJCL(student_emb_list, embd_queues, 128, 0.2 , 4, psi=4096)\n",
    "PCGJCL_loss = PCGJCL_loss.to(dev)\n",
    "print('PCGJCL_loss: ', PCGJCL_loss)\n",
    "\n",
    "model.module.contrast=False\n",
    "#calculate supervied loss\n",
    "imgs, multi_channel_masks =imgs.to(dev), multi_channel_masks.to(dev)\n",
    "out = model(imgs)\n",
    "print('masks shape: ', multi_channel_masks.shape)\n",
    "print('output shape: ', out.shape)\n",
    "\n",
    "supervised_loss = cross_entropy_loss(out,multi_channel_masks)\n",
    "supervised_loss = supervised_loss.to(dev)\n",
    "\n",
    "print('supervised_loss: ', supervised_loss)\n",
    "\n",
    "#total loss\n",
    "loss = supervised_loss + 0.5*PCGJCL_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_epochs in range(100): #100 epochs supervised pre training\n",
    "    step=0\n",
    "    min_loss = math.inf\n",
    "    epoch_loss=0\n",
    "    print('Epoch ',c_epochs)\n",
    "    \n",
    "    total_supervised_loss = 0\n",
    "    total_contrastive_loss = 0 \n",
    "    \n",
    "    for imgs, masks in labeled_loader:\n",
    "        print(\"masks shape: \", masks.shape)\n",
    "        # 創建一個新的形狀為 [8, 2, 256, 256] 的張量\n",
    "        multi_channel_masks = torch.zeros((masks.size(0), 2, masks.size(1), masks.size(2)), dtype=torch.float32)\n",
    "        # 將單通道遮罩轉換為多通道遮罩\n",
    "        multi_channel_masks[:, 0, :, :] = masks.float()  # 原始遮罩\n",
    "        multi_channel_masks[:, 1, :, :] = 1 - masks.float()  # 反轉遮罩\n",
    "\n",
    "        t1=time.time()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            #Send psudo masks & imgs to cpu\n",
    "            p_masks = multi_channel_masks\n",
    "            imgs = imgs\n",
    "\n",
    "            #get classwise patch list\n",
    "            patch_list = _get_patches(\n",
    "                imgs, p_masks,\n",
    "                classes=num_classes,\n",
    "                background=True,\n",
    "                img_size=img_size,\n",
    "                patch_size=contrastive_batch_size\n",
    "            )\n",
    "\n",
    "            #stochastic approximation filtering and threshold update\n",
    "            #qualified_patch_list = stochastic_approx.update(patch_list)\n",
    "            qualified_patch_list = patch_list\n",
    "\n",
    "            #make augmentations for teacher model\n",
    "            augmented_patch_list = batch_augment(qualified_patch_list,contrastive_batch_size)\n",
    "\n",
    "\n",
    "            #convert to tensor\n",
    "            aug_tensor_patch_list=[]\n",
    "            qualified_tensor_patch_list=[]\n",
    "            for i in range(len(augmented_patch_list)):\n",
    "                if augmented_patch_list[i] is not None:\n",
    "                    aug_tensor_patch_list.append(torch.tensor(augmented_patch_list[i]))\n",
    "                    qualified_tensor_patch_list.append(torch.tensor(qualified_patch_list[i]))\n",
    "                else:\n",
    "                    aug_tensor_patch_list.append(None)\n",
    "                    qualified_tensor_patch_list.append(None)\n",
    "\n",
    "\n",
    "        #get embeddings of qualified patches through student model\n",
    "        model=model.train()\n",
    "        model.module.contrast=True\n",
    "        student_emb_list = get_embeddings(model,qualified_tensor_patch_list,True)\n",
    "\n",
    "        #get embeddings of augmented patches through teacher model\n",
    "        teacher_model.train()\n",
    "        teacher_model.contrast = True\n",
    "        teacher_embedding_list = get_embeddings(teacher_model,aug_tensor_patch_list,False)\n",
    "\n",
    "        #enqueue these\n",
    "        embd_queues.enqueue(teacher_embedding_list)\n",
    "\n",
    "        #calculate PCGJCL loss\n",
    "        PCGJCL_loss = PCGJCL(student_emb_list, embd_queues, 128, 0.2 , 4, psi=4096)        \n",
    "        print('PCGJCL_loss: ', PCGJCL_loss.item())\n",
    "        \n",
    "        #calculate supervied loss\n",
    "        imgs, multi_channel_masks =imgs.to(dev), multi_channel_masks.to(dev)\n",
    "        model.module.contrast=False\n",
    "        out = model(imgs)\n",
    "        \n",
    "        supervised_loss = cross_entropy_loss(out,multi_channel_masks)\n",
    "        print('supervised_loss: ', supervised_loss.item())\n",
    "\n",
    "        #total loss\n",
    "        PCGJCL_loss = PCGJCL_loss.to(dev)\n",
    "        loss = supervised_loss + 0.5*PCGJCL_loss\n",
    "        \n",
    "        total_contrastive_loss += PCGJCL_loss.item()\n",
    "        total_supervised_loss += supervised_loss.item()\n",
    "        epoch_loss+=loss.item()\n",
    "\n",
    "        #backpropagate\n",
    "        loss.backward()\n",
    "        optimizer_pretrain.step()\n",
    "\n",
    "        for param_stud, param_teach in zip(model.parameters(),teacher_model.parameters()):\n",
    "            param_teach.data.copy_(0.001*param_stud + 0.999*param_teach)\n",
    "\n",
    "        #Extras\n",
    "        t2=time.time()\n",
    "        print('step ', step, 'loss: ',loss, ' & time: ',t2-t1)\n",
    "        step+=1\n",
    "        \n",
    "    avg_epoch_loss = epoch_loss / len(labeled_loader)\n",
    "    avg_supervised_loss = total_supervised_loss / len(labeled_loader)\n",
    "    avg_contrastive_loss = total_contrastive_loss / len(labeled_loader)\n",
    "    \n",
    "    save_loss(total_loss = f\"{avg_epoch_loss:.4f}\", \n",
    "          supervised_loss=f\"{avg_supervised_loss:.4f}\", \n",
    "          contrastive_loss=f\"{avg_contrastive_loss:.4f}\", \n",
    "          consistency_loss = 0 ,\n",
    "          filename=supervised_loss_path)\n",
    "    if epoch_loss < min_loss:\n",
    "        torch.save(model,'./best_contrast.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb99729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#enqueue these\u001b[39;00m\n\u001b[1;32m     84\u001b[0m embd_queues\u001b[38;5;241m.\u001b[39menqueue(teacher_embedding_list)\n\u001b[0;32m---> 85\u001b[0m PCGJCL_loss \u001b[38;5;241m=\u001b[39m \u001b[43mPCGJCL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_emb_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membd_queues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m     \n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#calculate supervied loss\u001b[39;00m\n\u001b[1;32m     88\u001b[0m imgs2, multi_channel_masks \u001b[38;5;241m=\u001b[39mimgs2\u001b[38;5;241m.\u001b[39mto(dev), multi_channel_masks\u001b[38;5;241m.\u001b[39mto(dev)\n",
      "File \u001b[0;32m~/PatchCL-MedSeg-jiyu/utils/plg_loss.py:53\u001b[0m, in \u001b[0;36mPCGJCL\u001b[0;34m(patch_list, embd_queues, emb_dim, tau, lamb, psi)\u001b[0m\n\u001b[1;32m     51\u001b[0m t_j, mu_j, sig_j\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(embd_queues[j], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), mean_list[j], cov_list[j]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#get hard neg mu_j,sig_j\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m hn_mu_j, hn_sig_j \u001b[38;5;241m=\u001b[39m \u001b[43mhard_neg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# GET HARD NEGS HERE\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#hn_mu_j, hn_sig_j = mu_j, sig_j # USE THIS FOR NO HARD NEGS\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l_count\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/PatchCL-MedSeg-jiyu/utils/hard_neg_mining.py:23\u001b[0m, in \u001b[0;36mhard_neg\u001b[0;34m(samples_p, mean_p, cov_p, samples_n, mean_n, cov_n, beta)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     t_p, mu_p, sig_p, t_n, mu_n, sig_n \u001b[38;5;241m=\u001b[39m samples_p\u001b[38;5;241m.\u001b[39mnumpy(), mean_p\u001b[38;5;241m.\u001b[39mnumpy(), cov_p\u001b[38;5;241m.\u001b[39mnumpy(), samples_n\u001b[38;5;241m.\u001b[39mnumpy(), mean_n\u001b[38;5;241m.\u001b[39mnumpy(), cov_n\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 23\u001b[0m     sig_p_inv, sig_n_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_p\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(sig_n)\n\u001b[1;32m     24\u001b[0m     sig_p_inv, sig_n_inv \u001b[38;5;241m=\u001b[39m sig_p_inv\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e10\u001b[39m, sig_n_inv\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e10\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# calculate mahalanobis dist and find anchors\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:1998\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap(res)\n\u001b[1;32m   1997\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m-> 1998\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhermitian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhermitian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;66;03m# discard small singular values\u001b[39;00m\n\u001b[1;32m   2001\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m rcond[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, newaxis] \u001b[38;5;241m*\u001b[39m amax(s, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:1657\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1656\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1657\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1659\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:98\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "for c_epochs in range(200): #200 epochs supervised SSL\n",
    "    step=0\n",
    "    min_loss = math.inf\n",
    "    epoch_loss=0\n",
    "    print('Epoch ',c_epochs)\n",
    "    \n",
    "    total_supervised_loss = 0\n",
    "    total_contrastive_loss = 0\n",
    "    total_consistency_loss = 0\n",
    "\n",
    "    labeled_iterator = iter(labeled_loader)\n",
    "    \n",
    "    for imgs in unlabeled_loader:\n",
    "\n",
    "        t1=time.time()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            #send imgs to dev\n",
    "            imgs = imgs.to(dev)\n",
    "\n",
    "            #set model in Eval mode\n",
    "            model = model.eval()\n",
    "\n",
    "            #Get pseudo masks\n",
    "            model.module.contrast=False\n",
    "            p_masks = model(imgs)\n",
    "\n",
    "            #Send psudo masks & imgs to cpu\n",
    "            p_masks=masks\n",
    "            p_masks = p_masks.to('cpu').detach()\n",
    "            imgs = imgs.to('cpu').detach()\n",
    "\n",
    "            #Since we use labeled data for PCGJCL as well\n",
    "            imgs2, masks2 = next(labeled_iterator)\n",
    "\n",
    "            #concatenating unlabeled and labeled sets\n",
    "            p_masks = torch.cat([p_masks,masks2],dim=0)\n",
    "            imgs = torch.cat([imgs,imgs2],dim=0)\n",
    "            \n",
    "            multi_channel_masks = torch.zeros((p_masks.size(0), 2, p_masks.size(1), p_masks.size(2)), dtype=torch.float32)\n",
    "            # 將單通道遮罩轉換為多通道遮罩\n",
    "            multi_channel_masks[:, 0, :, :] = p_masks.float()  # 原始遮罩\n",
    "            multi_channel_masks[:, 1, :, :] = 1 - p_masks.float()  # 反轉遮罩\n",
    "\n",
    "            #get classwise patch list\n",
    "            patch_list = _get_patches(\n",
    "                imgs, multi_channel_masks,\n",
    "                classes=num_classes,\n",
    "                background=True,\n",
    "                img_size=img_size,\n",
    "                patch_size=contrastive_batch_size\n",
    "            )\n",
    "\n",
    "            #stochastic approximation filtering and threshold update\n",
    "            qualified_patch_list = stochastic_approx.update(patch_list)\n",
    "\n",
    "\n",
    "            #make augmentations for teacher model\n",
    "            augmented_patch_list = batch_augment(qualified_patch_list,contrastive_batch_size)\n",
    "\n",
    "            #convert to tensor\n",
    "            aug_tensor_patch_list=[]\n",
    "            qualified_tensor_patch_list=[]\n",
    "            for i in range(len(augmented_patch_list)):\n",
    "                if augmented_patch_list[i] is not None:\n",
    "                    aug_tensor_patch_list.append(torch.tensor(augmented_patch_list[i]))\n",
    "                    qualified_tensor_patch_list.append(torch.tensor(qualified_patch_list[i]))\n",
    "                else:\n",
    "                    aug_tensor_patch_list.append(None)\n",
    "                    qualified_tensor_patch_list.append(None)\n",
    "\n",
    "\n",
    "        #get embeddings of qualified patches through student model\n",
    "        model=model.train()\n",
    "        model.module.contrast=True\n",
    "        student_emb_list = get_embeddings(model,qualified_tensor_patch_list,True)\n",
    "\n",
    "        #get embeddings of augmented patches through teacher model\n",
    "        teacher_model.train()\n",
    "        teacher_model.module.contrast = True\n",
    "        teacher_embedding_list = get_embeddings(teacher_model,aug_tensor_patch_list,False)\n",
    "\n",
    "        #enqueue these\n",
    "        embd_queues.enqueue(teacher_embedding_list)\n",
    "        PCGJCL_loss = PCGJCL(student_emb_list, embd_queues, 128, 0.2 , 4, psi=4096)     \n",
    "\n",
    "        #calculate supervied loss\n",
    "        imgs2, multi_channel_masks =imgs2.to(dev), multi_channel_masks.to(dev)\n",
    "        \n",
    "        model.module.contrast = False\n",
    "        out = model(imgs)\n",
    "        supervised_loss = cross_entropy_loss(out,multi_channel_masks)\n",
    "        \n",
    "        teacher_model.module.contrast = False\n",
    "        #Consistency Loss\n",
    "        consistency_loss=consistency_cost(model,teacher_model,imgs,multi_channel_masks)\n",
    "        \n",
    "        supervised_loss = supervised_loss.to(dev)\n",
    "        PCGJCL_loss = PCGJCL_loss.to(dev)\n",
    "        consistency_loss = consistency_loss.to(dev)\n",
    "        \n",
    "        total_supervised_loss += supervised_loss.item()\n",
    "        total_contrastive_loss += PCGJCL_loss.item()\n",
    "        total_consistency_loss += consistency_loss.item() \n",
    "        \n",
    "        print(\"supervised_loss: \", supervised_loss.item())\n",
    "        print(\"PCGJCL_loss: \", PCGJCL_loss.item())\n",
    "        print(\"consistency_loss: \", consistency_loss.item())\n",
    "        \n",
    "        #total loss\n",
    "        loss = supervised_loss + 0.5*PCGJCL_loss + 4*consistency_loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #backpropagate\n",
    "        loss.backward()\n",
    "        optimizer_ssl.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        for param_stud, param_teach in zip(model.parameters(),teacher_model.parameters()):\n",
    "            param_teach.data.copy_(0.001*param_stud + 0.999*param_teach)\n",
    "\n",
    "        #Extras\n",
    "        t2=time.time()\n",
    "        print('step ', step, 'loss: ',loss, ' & time: ',t2-t1)\n",
    "        step+=1\n",
    "        \n",
    "    avg_epoch_loss = epoch_loss / len(unlabeled_loader)\n",
    "    avg_supervised_loss = total_supervised_loss / len(unlabeled_loader)\n",
    "    avg_contrastive_loss = total_contrastive_loss / len(unlabeled_loader)\n",
    "    avg_consistency_loss = total_consistency_loss / len(unlabeled_loader)\n",
    "\n",
    "    save_loss(total_loss= f\"{avg_epoch_loss:.4f}\", \n",
    "              supervised_loss=f\"{avg_supervised_loss:.4f}\", \n",
    "              contrastive_loss=f\"{avg_contrastive_loss:.4f}\", \n",
    "              consistency_loss=f\"{avg_consistency_loss:.4f}\",\n",
    "              filename=SSL_loss_path)\n",
    "    \n",
    "    if epoch_loss < min_loss:\n",
    "        torch.save(model,'./best_contrast.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51a12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
